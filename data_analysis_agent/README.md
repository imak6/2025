# ğŸ§  Agent-Based Automated Data Analysis System

This project is a modular, intelligent data analysis system powered by **LangChain agents** and **local open-source LLMs** (like Mistral via Ollama). It can ingest a wide range of datasets, profile them, visualize trends, and generate human-readable insights automatically.

## Project Structure

DATA_ANALYSIS_AGENT/
â”œâ”€â”€ app.py
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data/...
â””â”€â”€ docker/
    â””â”€â”€ app.dockerfile

---

## ğŸ“Œ Features

- Load any tabular dataset (CSV, Excel, JSON, Parquet)
- Automatically profile and clean data
- Visualize key features and distributions
- Generate text-based summaries using LLMs
- Built with modular agents (LangChain)
- Works offline using local models (Mistral, LLaMA, etc.)

---

## ğŸ§± Architecture

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Input / Dataset    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
      (Dataset Loader Agent)
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Ingestion & Format  â”‚
â”‚ (CSV, Excel, Parquet...) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
   (Data Profiler Agent)
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Profiling (types, nulls,   â”‚
â”‚ basic stats, cardinality)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
     (Cleaning Agent)
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Suggestions/fixes (nulls,  â”‚
â”‚ outliers, type mismatches) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
   (EDA / Viz Agent)
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Generate plots, correlationsâ”‚
â”‚ distributions, time trends â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    (Insight Agent - LLM)
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Summary, anomalies, trends â”‚
â”‚ (LLM-generated text)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
      Optional: Modeling Agent
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ML modeling, AutoML, etc.  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Requirements

Install using pip (if you dont want to use docker):

```
pip install langchain-community langchain-ollama pandas openai pandas-profiling seaborn matplotlib streamlit
```

Local LLM (via Ollama)

macos: brew install ollama
others: <https://ollama.com>

Download and run a local model (e.g: Mistral, gemma:2b, qwen2.5)
```
"brew services start ollama"
"ollama run gemma:2b"
```
## Steps that get executed

- Define the LangChain agent pipeline using a local LLM via Ollama.

This script will:

- Load a dataset

- Run basic profiling

- Pass a data summary to the LLM agent (via LangChain)

- Output insights or suggestions

## Add Visualizations agent

- This agent will generate and optionally save visualizations (histograms, correlation heatmaps, bar plots)

## DOCKER INSTRUCTIONS TO HOST THE STREAMLIT APP

step1: Build docker image using the dockerfile
```
docker build -f docker/app.dockerfile -t data-anaysis-agent .
```  

step2: Run the Container (streamlit app)
```
docker run -p 8501:8501 data-agent-app
```
```
visit <http://localhost:8501>
```
step3: Push the created docker image to a repository (dockerhub/github container registry)
```
docker tag data-analysis-agent username/data-analysis-agent:latest
```

step4: login to docker hub
```
docker login
```

step5: Push the image
```
docker push username/data-analysis-agent:latest
```

step6: Run from the repository (Optional)
From any machine with docker installed:
**docker pull username/data-analysis-agent:latest** - pull the image pushed to docker hub

**docker run -p 8501:8501 username/data-analysis-agent:latest** - run the app/container

## Deployment with GitHub Actions

1. Setup Github Actions - check **.github/workflows/docker-deploy.yml** file.

2. Add Guthub Secrets

```
Github repo -> Settings -> Secrets -> Actions and Add:
- DOCKER_USERNAME
- DOCKER_PASSWORD
```

3. Push to main

- Once pushed to main branch, the image will be automatically built and pushed to docker hub.
